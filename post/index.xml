<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Portfolio home page</title>
    <link>https://mrodrigues17.github.io/post/</link>
    <description>Recent content in Projects on Portfolio home page</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 02 Mar 2017 12:00:00 -0500</lastBuildDate><atom:link href="https://mrodrigues17.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Movie Recommender System Using Content-Based Filtering</title>
      <link>https://mrodrigues17.github.io/post/chapter-1/</link>
      <pubDate>Thu, 11 Nov 2021 10:58:08 -0400</pubDate>
      
      <guid>https://mrodrigues17.github.io/post/chapter-1/</guid>
      <description>Used data take from IMDb to do feature engineering and create sparse matrices. Using cosine similarity, users select a vector of interest by indicating a movie title they like to get movie titles similar to the title they entered. The user can also specify the number of movies returned. UI file: controls user interface included the ability to select movie titles and the number of recommendations Server file: creates the output for the Shiny application data cleaning file: reads data from IMDb files and performs filtering and feature transformations  Github with UI, Server, and R data cleaning files available here</description>
    </item>
    
    <item>
      <title>Visualization of the Washington Post Police Killings Dataset</title>
      <link>https://mrodrigues17.github.io/post/chapter-2/</link>
      <pubDate>Sat, 30 Oct 2021 11:00:59 -0400</pubDate>
      
      <guid>https://mrodrigues17.github.io/post/chapter-2/</guid>
      <description>Police Killings Visualized The application shows police killing trends over the last few years (data collection began in 2015 by the Washington Post). Data is pulled directly from the Washington Post&amp;rsquo;s Github.
R code combines data from the US Census Bureau, application available here</description>
    </item>
    
    <item>
      <title>Machine Learning Algorithms Without Python ML Packages on a Binary Classification Task</title>
      <link>https://mrodrigues17.github.io/post/chapter-4/</link>
      <pubDate>Fri, 06 Sep 2019 11:14:48 -0400</pubDate>
      
      <guid>https://mrodrigues17.github.io/post/chapter-4/</guid>
      <description>For these projects, I am going to walk through the steps I went through in writing different algorithms for a binary classification task. Data cleaning and feature engineering steps aren&amp;rsquo;t included, these steps are just covering the algorithm. Below is a table showing the feature engineered, normalized data the algorithms are applied to: it is the introductory machine learning challenge dataset from Kaggle where features from Titanic ticket stubs are used to predict if a passenger died or survived the disaster.</description>
    </item>
    
    <item>
      <title>NBA Statistics R Shiny Application</title>
      <link>https://mrodrigues17.github.io/post/chapter-3/</link>
      <pubDate>Fri, 21 Jun 2019 11:13:32 -0400</pubDate>
      
      <guid>https://mrodrigues17.github.io/post/chapter-3/</guid>
      <description>Github link here
Code for a R Shiny application that visualizes NBA player statistics for easy visual comparison.
A link to the application is here
Data The Players file and player data file contain information about each player including height, weight, and college. The seasons stats file contains various NBA statistics for every player with playing time from 1950-2017.
R Files The UI file builds the user interface of the Shiny application.</description>
    </item>
    
  </channel>
</rss>
